---
title: "car_purchase"
author: "McKay Gerratt"
date: "July 28, 2020"
output: html_document
---

In this notebook I will be conducting an analysis for the Kaggle competition "Don't Get Kicked!" in which we are predicting whether or not a cars puchased at an auction actually function.

#Exploratory Data Analysis

```{r setup}

#Loading Packages
library(tidyverse)
library(caret)
```

```{r}
#reading in Data
train.pre <- read.csv("training.csv", stringsAsFactors = FALSE)
test.pre <- read.csv("test.csv", stringsAsFactors = FALSE)
# head(cbind(test.pre, "IsBadBuy" = NA))

to.clean <- rbind(cbind(train.pre[,-2], "IsBadBuy" = train.pre$IsBadBuy),
                  cbind(test.pre, "IsBadBuy" = NA))
```
```{r, eval = FALSE}
#testing how good zeroes are
write.csv(cbind("RefId" = test.pre$RefId, "IsBadBuy" = 0), "zero.csv", row.names = FALSE)



```


```{r}
str(to.clean)
#converting Purchase Date to Date type
to.clean$PurchDate <- as.Date(to.clean$PurchDate, format = "%M/%d/%Y")


to.numeric.names <- c("MMRAcquisitionAuctionAveragePrice", "MMRAcquisitionAuctionCleanPrice", "MMRAcquisitionRetailAveragePrice",
                     "MMRAcquisitonRetailCleanPrice", "MMRCurrentAuctionAveragePrice", "MMRCurrentAuctionCleanPrice", 
                     "MMRCurrentRetailAveragePrice", "MMRCurrentRetailCleanPrice")
to.clean[,to.numeric.names] <- sapply(to.clean[,to.numeric.names], as.numeric)

to.factor.names <- names(sapply(to.clean, is.character))[unname(sapply(to.clean,is.character))]
to.clean[,to.factor.names] <- lapply(to.clean[,to.factor.names], as.factor)

# to.clean[,to.numeric.names] <- lapply(to.clean[,to.numeric.names], function(x) {is.na(x) <- mean(x[!is.na(x)])})

for(i in to.numeric.names){
  to.clean[is.na(to.clean[,i]), i] <- mean(to.clean[,i], na.rm = TRUE)
}
```
```{r}
#seeing which values are missing
missing.values <- to.clean %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)

levels <-
    (missing.values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

percentage.plot <- missing.values %>%
      ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), 
                 stat = 'identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
      coord_flip() +
      labs(title = "Percentage of missing values", x =
             'Variable', y = "% of missing values")

percentage.plot


```

```{r}
# Columns to Remove
# I don't think trim will be important
unique(to.clean$Trim)
# There are 935 levels of SubModel. I don't think it will be very useful, but perhaps can get rid of excess
# unique(to.clean$SubModel)
# unique(to.clean$Color)
# length(to.clean$Color[to.clean$Color == "NULL"])
```

```{r}
#Variable Selection
to.delete.names <- c("Model", "Trim", "SubModel", "Color","WheelTypeID", "Make")
to.clean.post <- to.clean[, !names(to.clean) %in% to.delete.names]

too.correlated <- c("MMRAcquisitionAuctionCleanPrice", "MMRAcquisitionRetailAveragePrice",
                     "MMRAcquisitonRetailCleanPrice", "MMRCurrentAuctionAveragePrice", "MMRCurrentAuctionCleanPrice", 
                     "MMRCurrentRetailAveragePrice", "MMRCurrentRetailCleanPrice")
to.clean.post <- to.clean.post[, !names(to.clean.post) %in% too.correlated]

```

```{r}
# Breaking back into training and test sets
train <- to.clean.post[!is.na(to.clean.post$IsBadBuy),]
test <- to.clean.post[is.na(to.clean.post$IsBadBuy),]
# train$IsBadBuy <- as.factor(train$IsBadBuy)
table(train$IsBadBuy)
```
```{r}
# Correlation
corrgram::corrgram(train)
```



```{r}
#PurchDate
to.clean %>% filter(!is.na(IsBadBuy)) %>% group_by(PurchDate) %>% summarize(prop = sum(IsBadBuy)/length(PurchDate), num = sum(IsBadBuy)) %>% ungroup %>% as.data.frame %>% 
  ggplot(.)+geom_line(mapping = aes(x = PurchDate, y = prop), color = "blue") + 
  geom_line(mapping = aes(x = PurchDate, y = num), color = "red")


to.clean %>% filter(!is.na(IsBadBuy)) %>% ggplot() + geom_line(aes(x = PurchDate, y = IsBadBuy), color = "blue") +
  geom_line(aes(x = PurchDate,y = Is))
```


```{r}
#Exploratory Plots
#Age
train %>% dplyr::select(VehicleAge, IsBadBuy) %>% group_by(VehicleAge) %>% mutate(prop = round(length(VehicleAge)/nrow(train),3)) %>% ungroup() %>% 
  ggplot(.) + geom_bar(mapping = aes(x = VehicleAge, fill = as.factor(IsBadBuy)), position = "fill") +
  labs(title = "Distribution of Outcome by Age", y = "Percentage of Lemons", x = "Vehicle Age (Years)", fill = "Outcome") +
  geom_text(aes(x = VehicleAge, y = 0.5, label = prop, color = prop)) +
  scale_color_continuous(name = "perc of data", low = "red", high = "white") +
  scale_fill_manual(labels = c("Working", "Lemon"), values = c("black", "slateblue"))
```
```{r eval}
#Make
#doesn't seem to have a large correlation. The ones that seem to be higher do not have a large number of cars to speak of
train %>% select(Make, IsBadBuy) %>% group_by(Make) %>% mutate(prop = round(length(Make)/nrow(train),3)) %>% ungroup() %>% 
  ggplot(.) + geom_bar(mapping = aes(x = Make, fill = as.factor(IsBadBuy)), position = "fill") + #alpha = prop
  labs(title = "Distribution of Outcome by Make", y = "Percentage of Lemons", x = "Vehicle Age (Years)", fill = "Outcome") +
  geom_text(aes(x = Make, y = 0.5, label = prop, color = prop), angle = 90) +
  scale_color_continuous(name = "perc of data", low = "red", high = "white") +
  scale_fill_manual(labels = c("Working", "Lemon"), values = c("black", "slateblue")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5))
```
```{r}
#Transmission
#doesn't seem to have a large correlation
train %>% select(Transmission, IsBadBuy) %>% group_by(Transmission) %>% mutate(prop = round(length(Transmission)/nrow(train),3)) %>% ungroup() %>% 
  ggplot(.) + geom_bar(mapping = aes(x = Transmission, fill = as.factor(IsBadBuy)), position = "fill") + #alpha = prop
  labs(title = "Distribution of Outcome by Transmission", y = "Percentage of Lemons", x = "Vehicle Age (Years)", fill = "Outcome") +
  geom_text(aes(x = Transmission, y = 0.5, label = prop, color = prop), angle = 90) +
  scale_color_continuous(name = "perc of data", low = "red", high = "white") +
  scale_fill_manual(labels = c("Working", "Lemon"), values = c("black", "slateblue")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = 0.5))

round(table(train[,c("IsBadBuy", "Transmission")])/nrow(train),2)
```
```{r}
# AUGUART
to.clean %>% filter(!is.na(IsBadBuy)) %>% select(AUCGUART, IsBadBuy) %>% #group_by(PRIMEUNIT) %>% mutate(prop = round(length(PRIMEUNIT)/nrow(train),3)) %>% ungroup() %>% 
  ggplot(.) + geom_bar(mapping = aes(x = as.factor(AUCGUART), fill = as.factor(IsBadBuy)), position = "fill")

round(table(train[,c("IsBadBuy", "Transmission")])/nrow(train),2)
```

```{r}
# PRIMEUNIT
to.clean %>% filter(!is.na(IsBadBuy)) %>% select(PRIMEUNIT, IsBadBuy) %>% #group_by(PRIMEUNIT) %>% mutate(prop = round(length(PRIMEUNIT)/nrow(train),3)) %>% ungroup() %>% 
  ggplot(.) + geom_bar(mapping = aes(x = as.factor(PRIMEUNIT), fill = as.factor(IsBadBuy)), position = "fill")

round(table(train[,c("IsBadBuy", "Transmission")])/nrow(train),2)
```

```{r}
train %>% select(-starts_with("MMR")) %>% colnames
```

```{r}
# perc.plot <- function(x, y = IsBadBuy, df = train) {
#   attach(df)
#   train %>% select(((x)), ((y)))
#     #                %>% group_by(x) %>% mutate(prop = round(length(x)/nrow(df),3)) %>% ungroup() %>% 
#     # ggplot(.) + geom_bar(mapping = aes(x = x, fill = as.factor(y)), position = "fill") +
#     # labs(title = "Distribution of Outcome by Age", y = "Percentage of Lemons", x = "Vehicle Age (Years)", fill = "Outcome") +
#     # geom_text(aes(x = x, y = 0.5, label = prop, color = prop)) +
#     # scale_color_continuous(name = "perc of data", low = "red", high = "white") +
#     # scale_fill_manual(labels = c("Working", "Lemon"), values = c("black", "slateblue"))
# }
```
```{r}
# perc.plot(VehicleAge, IsBadBuy, train) %>% head
```


#Jitter Plots
```{r}
jitter.plot <- train %>% gather(-IsBadBuy, key = "var", value = "value") %>% 
  ggplot(mapping = aes(x = value, y = IsBadBuy)) + geom_point() + geom_jitter(width = .4, height = .1) + geom_smooth(se = FALSE) + facet_wrap(~var, scales = "free")

smooth.plot <- train %>% gather(-IsBadBuy, key = "var", value = "value") %>% 
  ggplot(mapping = aes(x = value, y = IsBadBuy)) + geom_point(aes(color = var)) + geom_smooth(method = "nls", formula = y ~ a * x + b, se = F,
              method.args = list(start = list(a = 0.1, b = 0.1))) + facet_wrap(~var, scales = "free")

train %>% gather(-IsBadBuy, key = "var", value = "value") %>% filter(var == "IsOnlineSale") %>% 
  ggplot(mapping = aes(x = value)) + geom_density() #+ facet_wrap(~var, scales = "free")


```




#Fitting Models
```{r}
#GBM 1
set.seed(7282020)
myControl <- trainControl(method = "cv", number = 3, allowParallel = TRUE)
myGrid <- expand.grid(n.trees = c(50),#, 100), 
                      interaction.depth = c(5),#,7), 
                      shrinkage = c(0.01),#, 0.1), 
                      n.minobsinnode = c(1))#, 10))

gbm.2 <- train(as.factor(IsBadBuy) ~.-RefId-PurchDate,
               data = train,
               method = "gbm",
               tuneGrid = myGrid,
               trControl = myControl
               #na.action = na.pass
               )

gbm.2.preds <- predict(gbm.2, test, type = "prob")[,1]
gbm.2.preds.post <- as.integer(gbm.2.preds  < quantile(gbm.2.preds, .13))
write.csv(cbind("RefId" = test$RefId, "IsBadBuy" = gbm.2.preds.post), "gbm.2.preds.csv", row.names = FALSE)

# train(as.factor(Cover_Type)~.-Id,
#                    data = train,
#                    method = "xgbTree",
#                    tuneGrid = tunegrid,
#                    trControl = myControl,
#                    metric = "Accuracy"
# )
```

```{r}
#GBM 2
set.seed(8112020)
myControl <- trainControl(method = "cv", number = 3, allowParallel = TRUE)
myGrid <- expand.grid(n.trees = c(50, 100, 150), 
                      interaction.depth = c(5, 7, 9),
                      shrinkage = c(0.01, .1),
                      n.minobsinnode = c(1, 10))

gbm.3 <- train(as.factor(IsBadBuy) ~.-RefId-PurchDate,
               data = train,
               method = "gbm",
               tuneGrid = myGrid,
               trControl = myControl
               #na.action = na.pass
               )

gbm.3.preds <- predict(gbm.3, test, type = "prob")[,1]
gbm.3.preds.post <- as.integer(gbm.3.preds  < quantile(gbm.3.preds, .13))
write.csv(cbind("RefId" = test$RefId, "IsBadBuy" = gbm.3.preds.post), "gbm.3.preds.csv", row.names = FALSE)
```

```{r}

caret.gini <- function (data, lev=NULL, model=NULL) {
  gini <- function(t, p) {
    n <- length(t)
    df <- data.frame(true=t, pred=p)
    df <- df[order(-df$pred, 1:n, decreasing=T), ]
    null.losses <- rep(1/n, n)
    total.losses <- sum(t)
    accum.losses <- df$true / total.losses
    gini.sum <- cumsum(accum.losses - null.losses)
    sum(gini.sum) / n
  }
  out <- gini(data$obs, data$pred) / gini(data$obs, data$obs) 
  names(out) <- "GINI"
  out
}

custom_summary <- function(data, lev = NULL, model = NULL) {
  # out <- Metrics::rmsle(data[, "obs"], data[, "pred"])
  out <- DescTools::Gini(data$)
  names(out) <- c("GINI")
  out
}

normalizedGini <- function(aa, pp) {
    Gini <- function(a, p) {
        if (length(a) !=  length(p)) stop("Actual and Predicted need to be equal lengths!")
        temp.df <- data.frame(actual = a, pred = p, range=c(1:length(a)))
        temp.df <- temp.df[order(-temp.df$pred, temp.df$range),]
        population.delta <- 1 / length(a)
        total.losses <- sum(a)
        null.losses <- rep(population.delta, length(a)) # Hopefully is similar to accumulatedPopulationPercentageSum
        accum.losses <- temp.df$actual / total.losses # Hopefully is similar to accumulatedLossPercentageSum
        gini.sum <- cumsum(accum.losses - null.losses) # Not sure if this is having the same effect or not
        sum(gini.sum) / length(a)
    }
    Gini(aa,pp) / Gini(aa,aa)
}

# create the normalized gini summary function to pass into caret
giniSummary <- function (data, lev = "Yes", model = NULL) {
    levels(data$obs) <- c('0', '1')
    out <- normalizedGini(as.numeric(levels(data$obs))[data$obs], data[, lev[2]])  
    names(out) <- "NormalizedGini"
    out
}
```
```{r}
#GBM 3
set.seed(8132020)
myControl <- trainControl(method = "cv", number = 3, allowParallel = TRUE)
myGrid <- expand.grid(n.trees = c(50, 100, 150), 
                      interaction.depth = c(5, 7, 9),
                      shrinkage = c(0.01, .1),
                      n.minobsinnode = c(1, 10))

gbm.4 <- train(as.factor(IsBadBuy) ~.-RefId-PurchDate,
               data = train,
               method = "gbm",
               tuneGrid = myGrid,
               trControl = myControl,
               preProcess = c("nzv", "zv", "center", "scale")
               #na.action = na.pass
               )

gbm.4.preds <- predict(gbm.4, test, type = "prob")[,1]
gbm.4.preds.post <- as.integer(gbm.4.preds  < quantile(gbm.4.preds, .13))
write.csv(cbind("RefId" = test$RefId, "IsBadBuy" = gbm.4.preds.post), "gbm.4.preds.csv", row.names = FALSE)
```

```{r}
#GBM 3
set.seed(8132020)
myControl <- trainControl(method = "cv", number = 3, allowParallel = TRUE, verboseIter = TRUE, summaryFunction = giniSummary)
myGrid <- expand.grid(n.trees = c(150), 
                      interaction.depth = c(9),
                      shrinkage = c(.1),
                      n.minobsinnode = c(1))

gbm.5 <- train(as.factor(IsBadBuy) ~.-RefId-PurchDate,
               data = train,
               method = "gbm",
               tuneGrid = myGrid,
               trControl = myControl,
               preProcess = c("nzv", "zv", "center", "scale"),
               metric = "NormalizedGini"
               #na.action = na.pass
               )

gbm.5.preds <- predict(gbm.5, test, type = "prob")[,1]
gbm.5.preds.post <- as.integer(gbm.5.preds  < quantile(gbm.5.preds, .13))
sum(gbm.5.preds.post)/length(gbm.5.preds.post)
write.csv(cbind("RefId" = test$RefId, "IsBadBuy" = gbm.5.preds.post), "gbm.5.preds.csv", row.names = FALSE)
```


